<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Week 10 - Modeling Data and More Shiny</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alex Lishinski" />
    <meta name="date" content="2021-10-19" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link rel="stylesheet" href="theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Week 10 - Modeling Data and More Shiny
### Alex Lishinski
### October 19, 2021

---




# Welcome!

Welcome to *week 11*!



**Record the meeting** 



---

### Topics for today

**Record the meeting** 

Modeling continued

A. Recap from the buffet and further expansion

B. Model outputs and summaries

C. Model helpers - tests, diagnostics, and model components

D. Shiny continued

---

### A. Buffet of models recap

What a model is:

**model**: a simplified _representation_ of your data that
can be informative to you (and others) about your data - and, maybe, what your data
represents. 

From this broad definition, models can take many different forms:

- A sample statistic (e.g., a _mean_ of a variable)
- A relationship describing how two variables co-vary (e.g., a bivariate _correlation_)
- A linear regression model

---

### A. Buffet of models recap

How do we represent model equations in R? Many R packages share a common modeling syntax, or interface: the formula syntax.

This code represents the regression of `hp` upon `mpg`:


```r
mpg ~ hp
```

Then there are other formula operators:


```r
# additional independent variables
mpg ~ hp + disp
# interactions with main effects
mpg ~ hp + disp + hp*disp
# interactions without main effects
mpg ~ hp + disp + hp:disp
# All remaining variables
mpg ~ .
```

---

### A. Buffet of models recap

There are a number of helper functions that work with `lm` and other models

And there's some more advanced formula tricks too


```r
# Polynomial Regression
y ~ x + I(x^2) + I(x^3)
```

```
## y ~ x + I(x^2) + I(x^3)
```

```r
# Factorial ANOVA
y ~ (a*b*c)^2
```

```
## y ~ (a * b * c)^2
```

```r
# Variable transformations
Sepal.Width ~ Petal.Width + log(Petal.Length) + Species
```

```
## Sepal.Width ~ Petal.Width + log(Petal.Length) + Species
```

---

### A. Buffet of models recap

The lm() function is the base case of using these model formulas



Estimating a model; seeing the result:


```r
lm(FinalGradeCEMS ~ TimeSpent_hours, data = d)
```

```
## 
## Call:
## lm(formula = FinalGradeCEMS ~ TimeSpent_hours, data = d)
## 
## Coefficients:
##     (Intercept)  TimeSpent_hours  
##         65.8085           0.3648
```

---

### A. Buffet of models recap

The lm() function is the base case of using these model formulas

Saving the output to an _object_ and printing a summary of the results


```r
m1 &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours, data = d)
summary(m1)
```

```
## 
## Call:
## lm(formula = FinalGradeCEMS ~ TimeSpent_hours, data = d)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -67.136  -7.805   4.723  14.471  30.317 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     65.80851    1.49120   44.13   &lt;2e-16 ***
## TimeSpent_hours  0.36484    0.03889    9.38   &lt;2e-16 ***
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 20.71 on 571 degrees of freedom
##   (30 observations deleted due to missingness)
## Multiple R-squared:  0.1335,	Adjusted R-squared:  0.132 
## F-statistic: 87.99 on 1 and 571 DF,  p-value: &lt; 2.2e-16
```

---

### A. Buffet of models recap

The lm() function is the base case of using these model formulas

Making the model more complex - a multiple regression


```r
m2 &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours + int + Gender, data = d)
summary(m2)
```

```
## 
## Call:
## lm(formula = FinalGradeCEMS ~ TimeSpent_hours + int + Gender, 
##     data = d)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -66.593  -7.382   4.761  14.534  30.618 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     69.61325    7.06075   9.859   &lt;2e-16 ***
## TimeSpent_hours  0.36962    0.04198   8.804   &lt;2e-16 ***
## int             -0.99359    1.58756  -0.626    0.532    
## GenderM         -0.54962    2.06489  -0.266    0.790    
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 21.03 on 499 degrees of freedom
##   (100 observations deleted due to missingness)
## Multiple R-squared:  0.1375,	Adjusted R-squared:  0.1323 
## F-statistic: 26.51 on 3 and 499 DF,  p-value: 6.362e-16
```

---

### A. Buffet of models recap

But other functions and packages use this as well

t-test


```r
m_t_test &lt;- t.test(FinalGradeCEMS ~ Gender, data = d)
m_t_test
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  FinalGradeCEMS by Gender
## t = -0.30379, df = 327.71, p-value = 0.7615
## alternative hypothesis: true difference in means between group F and group M is not equal to 0
## 95 percent confidence interval:
##  -4.579370  3.354211
## sample estimates:
## mean in group F mean in group M 
##        77.01877        77.63135
```

ANOVA


```r
m_anova &lt;- aov(FinalGradeCEMS ~ subject, data = d)
m_anova
```

```
## Call:
##    aov(formula = FinalGradeCEMS ~ subject, data = d)
## 
## Terms:
##                   subject Residuals
## Sum of Squares   13484.46 269057.23
## Deg. of Freedom         4       568
## 
## Residual standard error: 21.76447
## Estimated effects may be unbalanced
## 30 observations deleted due to missingness
```

---

### A. Buffet of models recap

Some packages add to this syntax too -- Multi-level model


```r
library(lme4)
m5 &lt;- lmer(FinalGradeCEMS ~ TimeSpent_hours + int*Gender + (1|course_id), data = d)
summary(m5)
```

```
## Linear mixed model fit by REML ['lmerMod']
## Formula: 
## FinalGradeCEMS ~ TimeSpent_hours + int * Gender + (1 | course_id)
##    Data: d
## 
## REML criterion at convergence: 4433.8
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.4970 -0.4169  0.2413  0.6507  2.3171 
## 
## Random effects:
##  Groups    Name        Variance Std.Dev.
##  course_id (Intercept)  46.47    6.817  
##  Residual              384.21   19.601  
## Number of obs: 503, groups:  course_id, 26
## 
## Fixed effects:
##                  Estimate Std. Error t value
## (Intercept)      74.22969    8.45385   8.781
## TimeSpent_hours   0.43078    0.04128  10.435
## int              -2.84129    1.89455  -1.500
## GenderM         -26.55507   13.10001  -2.027
## int:GenderM       6.39449    3.09236   2.068
## 
## Correlation of Fixed Effects:
##             (Intr) TmSpn_ int    GendrM
## TimSpnt_hrs -0.239                     
## int         -0.963  0.091              
## GenderM     -0.595  0.021  0.611       
## int:GenderM  0.583 -0.027 -0.609 -0.989
```

---

### A. Buffet of models recap

Weights using `lm()`


```r
# Adding weights
wts1 &lt;- rnorm(n = nrow(d), mean = 0, sd = 1)
wts2 &lt;- rnorm(n = nrow(d), mean = 0, sd = 1)

wts &lt;- abs(wts1/wts2)

m1_wt &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours, data = d, weights = wts)
summary(m1_wt)
```

```
## 
## Call:
## lm(formula = FinalGradeCEMS ~ TimeSpent_hours, data = d, weights = wts)
## 
## Weighted Residuals:
##      Min       1Q   Median       3Q      Max 
## -286.678   -8.548    3.008   12.598  182.823 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     68.98517    1.19727  57.619  &lt; 2e-16 ***
## TimeSpent_hours  0.30513    0.03885   7.853 2.02e-14 ***
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 36.64 on 571 degrees of freedom
##   (30 observations deleted due to missingness)
## Multiple R-squared:  0.09748,	Adjusted R-squared:  0.0959 
## F-statistic: 61.67 on 1 and 571 DF,  p-value: 2.021e-14
```


---

### A. Buffet of models recap

The `glm()` function - the way to fit other types of regression models

`glm()` lets you specify distribution families for different kinds of outcomes:

* "gaussian" = standard regression for continuous dependent variables (default)
* "binomial" = binary (0/1) outcome variables
* "poisson" = count outcome variables
* several others are available

---

### A. Buffet of models recap

The base case with default options will be same as `lm()`


```r
glm1 &lt;- glm(FinalGradeCEMS ~ TimeSpent_hours, data = d)
summary(glm1)
```

```
## 
## Call:
## glm(formula = FinalGradeCEMS ~ TimeSpent_hours, data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -67.136   -7.805    4.723   14.471   30.317  
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     65.80851    1.49120   44.13   &lt;2e-16 ***
## TimeSpent_hours  0.36484    0.03889    9.38   &lt;2e-16 ***
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 428.7479)
## 
##     Null deviance: 282542  on 572  degrees of freedom
## Residual deviance: 244815  on 571  degrees of freedom
##   (30 observations deleted due to missingness)
## AIC: 5103
## 
## Number of Fisher Scoring iterations: 2
```

---

### A. Buffet of models recap

The `family` argument to `glm()` helps you change the kind of model being estimated.


```r
d &lt;- d %&gt;%
  mutate(Points_Earned_Bin = ifelse(d$Points_Earned &gt; mean(d$Points_Earned, na.rm = T), 1, 0))

glm1 &lt;- glm(Points_Earned_Bin ~ TimeSpent_hours, data = d, family = "binomial")
summary(glm1)
```

```
## 
## Call:
## glm(formula = Points_Earned_Bin ~ TimeSpent_hours, family = "binomial", 
##     data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.6393  -0.6166  -0.5992  -0.5624   2.0446  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -1.484105   0.199288  -7.447 9.55e-14 ***
## TimeSpent_hours -0.004482   0.005535  -0.810    0.418    
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 455.26  on 506  degrees of freedom
## Residual deviance: 454.58  on 505  degrees of freedom
##   (96 observations deleted due to missingness)
## AIC: 458.58
## 
## Number of Fisher Scoring iterations: 4
```

---

### B. Model outputs and summaries

We've previously discussed making better looking output tables in .Rmd documents


```r
library(sjPlot)

tab_model(m1)
```

&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;&amp;nbsp;&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;Final Grade CEMS&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;Predictors&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;Estimates&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;CI&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;p&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;(Intercept)&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;65.81&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;62.88&amp;nbsp;&amp;ndash;&amp;nbsp;68.74&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;TimeSpent_hours&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;0.36&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;0.29&amp;nbsp;&amp;ndash;&amp;nbsp;0.44&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;Observations&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;573&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;0.134 / 0.132&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

---

### B. Model outputs and summaries

Another package makes it easier to pull out model estimates in an easier format to use for further operations: `broom`

`tidy()` Makes `lm()` coefficient output into a tidy data frame format, which you can then use all of your tidyverse tools on

`glance()` works similarly but with the whole model diagnostic statistics such as `\(R^2\)`


```r
library(broom)

# Model coefficents
tidy(m1)
```

```
## # A tibble: 2 × 5
##   term            estimate std.error statistic   p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       65.8      1.49       44.1  3.71e-186
## 2 TimeSpent_hours    0.365    0.0389      9.38 1.53e- 19
```

```r
# whole model stats
glance(m1)
```

```
## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic  p.value    df
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
## 1     0.134         0.132  20.7      88.0 1.53e-19     1
## # … with 6 more variables: logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,
## #   BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;,
## #   nobs &lt;int&gt;
```


---

### B. Model outputs and summaries

`broom` can also help you grab other diagnostics from the model with `augment()`


```r
# Data level additional model generated values
head(augment(m1))
```

```
## # A tibble: 6 × 9
##   .rownames FinalGradeCEMS TimeSpent_hours .fitted .resid
##   &lt;chr&gt;              &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 1                   93.5            25.9    75.3  18.2 
## 2 2                   81.7            23.0    74.2   7.49
## 3 3                   88.5            14.3    71.0  17.4 
## 4 4                   81.9            26.6    75.5   6.32
## 5 5                   84              24.7    74.8   9.18
## 6 7                   83.6            22.0    73.8   9.74
## # … with 4 more variables: .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;,
## #   .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;
```

---

### B. Model outputs and summaries

`broom` can also help you grab other diagnostics from the model



```r
f &lt;- augment(m1)

ggplot(f) +
  geom_point(aes(x=.fitted, y=.resid))
```

&lt;img src="week10-slides_files/figure-html/unnamed-chunk-20-1.png" width="50%" style="display: block; margin: auto;" /&gt;

---

### B. Model outputs and summaries

The `car` package has plotting and testing functions that can help you evaluate models


```r
library(car)

avPlots(m2)
```

&lt;img src="week10-slides_files/figure-html/unnamed-chunk-21-1.png" width="50%" style="display: block; margin: auto;" /&gt;

---

### B. Model outputs and summaries

The `car` package has plotting and testing functions that can help you evaluate models


```r
residualPlots(m2)
```

&lt;img src="week10-slides_files/figure-html/unnamed-chunk-22-1.png" width="50%" style="display: block; margin: auto;" /&gt;

```
##                 Test stat Pr(&gt;|Test stat|)    
## TimeSpent_hours   -6.3056        6.337e-10 ***
## int               -1.7279          0.08462 .  
## Tukey test        -6.3520        2.125e-10 ***
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

### B. Model outputs and summaries

The `report` package can generate written summaries of the results of your models


```r
#devtools::install_github("https://github.com/easystats/report")
library(report)

report(m1)
```

```
## We fitted a linear model (estimated using OLS) to predict FinalGradeCEMS with TimeSpent_hours (formula: FinalGradeCEMS ~ TimeSpent_hours). The model explains a statistically significant and moderate proportion of variance (R2 = 0.13, F(1, 571) = 87.99, p &lt; .001, adj. R2 = 0.13). The model's intercept, corresponding to TimeSpent_hours = 0, is at 65.81 (95% CI [62.88, 68.74], t(571) = 44.13, p &lt; .001). Within this model:
## 
##   - The effect of TimeSpent_hours is statistically significant and positive (beta = 0.36, 95% CI [0.29, 0.44], t(571) = 9.38, p &lt; .001; Std. beta = 0.37, 95% CI [0.29, 0.44])
## 
## Standardized parameters were obtained by fitting the model on a standardized version of the dataset.
```

---

### B. Model outputs and summaries

Components of an `lm()` object, some of which you can get with helper functions


```r
m1$coefficients
```

```
##     (Intercept) TimeSpent_hours 
##      65.8085094       0.3648365
```

```r
head(m1$residuals)
```

```
##         1         2         3         4         5         7 
## 18.188854  7.485674 17.447115  6.323524  9.181244  9.742307
```

---

### C. Model helpers - tests, diagnostics, etc.

There are a number of helper functions that work with `lm` and other models


```r
# model coefficients
coef(m1)
```

```
##     (Intercept) TimeSpent_hours 
##      65.8085094       0.3648365
```

```r
# model residuals
head(residuals(m1))
```

```
##         1         2         3         4         5         7 
## 18.188854  7.485674 17.447115  6.323524  9.181244  9.742307
```

```r
# regression fitted values
head(fitted(m1))
```

```
##        1        2        3        4        5        7 
## 75.26487 74.21617 71.04047 75.52907 74.81876 73.84596
```

```r
# Get the data used to fit the model
head(model.frame(m1))
```

```
##   FinalGradeCEMS TimeSpent_hours
## 1       93.45372        25.91944
## 2       81.70184        23.04500
## 3       88.48758        14.34056
## 4       81.85260        26.64361
## 5       84.00000        24.69667
## 7       83.58827        22.03027
```

---

### C. Model helpers - tests, diagnostics, etc.

There are a number of helper functions that work with `lm` and other models - How do we know which ones?


```r
library(sloop)
s3_methods_class("lm")
```

```
## # A tibble: 86 × 4
##    generic       class visible source             
##    &lt;chr&gt;         &lt;chr&gt; &lt;lgl&gt;   &lt;chr&gt;              
##  1 add1          lm    FALSE   registered S3method
##  2 alias         lm    FALSE   registered S3method
##  3 anova         lm    FALSE   registered S3method
##  4 Anova         lm    FALSE   registered S3method
##  5 as.data.frame lm    FALSE   registered S3method
##  6 augment       lm    FALSE   registered S3method
##  7 avPlot        lm    FALSE   registered S3method
##  8 Boot          lm    FALSE   registered S3method
##  9 bootCase      lm    FALSE   registered S3method
## 10 boxCox        lm    FALSE   registered S3method
## # … with 76 more rows
```

```r
confint(m1)
```

```
##                      2.5 %    97.5 %
## (Intercept)     62.8796038 68.737415
## TimeSpent_hours  0.2884451  0.441228
```

```r
vcov(m1)
```

```
##                 (Intercept) TimeSpent_hours
## (Intercept)      2.22367608    -0.047242592
## TimeSpent_hours -0.04724259     0.001512691
```

---

### C. Model helpers - tests, diagnostics, etc.

The `lmSupport` package provides number of additional tools for regression models


```r
library(lmSupport)

m1 &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours, data = d)
m2 &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours + int + Gender, data = d)

# A function to check regression model assumptions
modelAssumptions(m1)
```

```
## Descriptive Statistics for Studentized Residuals
## 
## Call:
## lm(formula = FinalGradeCEMS ~ TimeSpent_hours, data = d)
## 
## Coefficients:
##     (Intercept)  TimeSpent_hours  
##         65.8085           0.3648  
## 
## 
## ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS
## USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:
## Level of Significance =  0.05 
## 
## Call:
##  gvlma(x = Model) 
## 
##                     Value   p-value
## Global Stat        313.26 0.000e+00
## Skewness           182.13 0.000e+00
## Kurtosis            69.89 1.110e-16
## Link Function       40.33 2.143e-10
## Heteroscedasticity  20.91 4.820e-06
##                                      Decision
## Global Stat        Assumptions NOT satisfied!
## Skewness           Assumptions NOT satisfied!
## Kurtosis           Assumptions NOT satisfied!
## Link Function      Assumptions NOT satisfied!
## Heteroscedasticity Assumptions NOT satisfied!
```

---

### C. Model helpers - tests, diagnostics, etc.

The `lmSupport` package provides number of additional tools for regression models


```r
m2 &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours + int + Gender, data = d)
m1 &lt;- lm(FinalGradeCEMS ~ TimeSpent_hours, data = model.frame(m2$model))

# F Test difference between 2 models
modelCompare(m1, m2)
```

```
## SSE (Compact) =  220820.1 
## SSE (Augmented) =  220624.9 
## Delta R-Squared =  0.0007632935 
## Partial Eta-Squared (PRE) =  0.0008841496 
## F(2,499) = 0.2207905, p = 0.8019629
```

---

### D. Shiny Continued

*Storms App Additional Features*

Fixing the multiple hurricanes issue 

Adding a zoom slider

Adding Color

Data table under plot

---

### Addendum: Other modeling packages to be aware of

* `lme4` and `nlme`: hierarchical linear models (aka multilevel models)
* `lavaan`: structural equation models
* `MASS`: Robust regression
* `caret`: Lots of different classification and regression models for machine learning applications
* `parsnip`: (tidyverse) Unified interface to many different models, largely machine learning type
* Time series: https://cran.r-project.org/web/views/TimeSeries.html

Other types of models that may be more applicable to your field can also be found in the CRAN task views:
https://cran.r-project.org/web/views/

Tutorials for many different varieties of Regression can be found here: 
https://stats.idre.ucla.edu/other/dae/

Other packages that can help you with your models
https://easystats.github.io/easystats/
e.g. the `performance` package does model assumption checking and model comparison

---

# Logistics

**This week**

* Homework 8: Available tomorrow, Due next Tuesday 

* Reading: * https://www.tmwr.org/base-r.html#formula

---

# Assignment updates

* [Final project](https://f21-intro-to-data-sci-methods-in-ed.netlify.app/assignment-final-project/)
  * NEXT Thursday - Give updated version of your idea 

---

### Wrapping up

On Slack channel:

- What is one thing you learned today?
- What is something you want to learn more about? 
- Share your feelings in GIF form!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
